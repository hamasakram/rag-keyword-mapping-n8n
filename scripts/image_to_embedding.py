import os
import sys
import json
import psycopg2
from psycopg2.extras import Json
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

def main():
    if len(sys.argv) < 2:
        print("Usage: python scripts/image_to_embedding.py <image_path> [--store] [--topk N]")
        sys.exit(1)

    image_path = sys.argv[1]
    store = "--store" in sys.argv
    # optional retrieval args
    topk = 0
    if "--topk" in sys.argv:
        try:
            idx = sys.argv.index("--topk")
            topk = int(sys.argv[idx + 1])
        except Exception:
            print("Warning: invalid --topk value, ignoring")
            topk = 0

    if not os.path.exists(image_path):
        print(f"Error: image not found at {image_path}")
        sys.exit(1)

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("Error: GEMINI_API_KEY environment variable not set")
        sys.exit(1)
    genai.configure(api_key=api_key)

    # 1) Describe the image using Gemini Vision
    with open(image_path, 'rb') as f:
        image_bytes = f.read()

    model = genai.GenerativeModel("gemini-1.5-pro")
    prompt = "Describe the product in this image. Focus on product type, brand, features, materials, style, and use-case. Keep it concise but informative."
    response = model.generate_content([
        prompt,
        {"mime_type": "image/jpeg", "data": image_bytes}
    ])
    description = response.text.strip() if hasattr(response, 'text') else ""

    if not description:
        print("Error: No description generated by Gemini Vision")
        sys.exit(1)

    print("Description:\n" + description)

    # 2) Embed the description using the same 768D embedding model
    emb_resp = genai.embed_content(
        model="models/embedding-001",
        content=description
    )
    embedding = emb_resp['embedding']

    if not store and topk <= 0:
        print(json.dumps({
            "image": os.path.basename(image_path),
            "description": description,
            "embedding_dim": len(embedding)
        }, ensure_ascii=False))
        return

    # 3) Optional: store and/or retrieve similar keywords
    conn = psycopg2.connect(
        dbname=os.getenv("PGDATABASE", "rag_keywords"),
        user=os.getenv("PGUSER", "postgres"),
        password=os.getenv("PGPASSWORD", "postgres"),
        host=os.getenv("PGHOST", "localhost"),
        port=os.getenv("PGPORT", 5432),
    )
    cur = conn.cursor()

    new_id = None
    if store:
        cur.execute(
            """
            INSERT INTO product_descriptions (image_name, description, embedding, meta)
            VALUES (%s, %s, %s, %s)
            RETURNING id
            """,
            (
                os.path.basename(image_path),
                description,
                embedding,
                Json({"source_path": image_path})
            )
        )
        new_id = cur.fetchone()[0]
        conn.commit()

    results = None
    if topk and topk > 0:
        # cosine distance: smaller is more similar
        cur.execute(
            """
            SELECT keyword, 1 - (embedding <=> %s::vector) AS similarity
            FROM keywords
            WHERE embedding IS NOT NULL
            ORDER BY embedding <=> %s::vector
            LIMIT %s
            """,
            (embedding, embedding, topk)
        )
        rows = cur.fetchall()
        results = [
            {"keyword": r[0], "similarity": float(r[1])}
            for r in rows
        ]

    cur.close()
    conn.close()

    output = {
        "image": os.path.basename(image_path),
        "description": description,
        "embedding_dim": len(embedding)
    }
    if new_id is not None:
        output["stored_id"] = new_id
    if results is not None:
        output["topk_keywords"] = results

    print(json.dumps(output, ensure_ascii=False))

if __name__ == "__main__":
    main()


